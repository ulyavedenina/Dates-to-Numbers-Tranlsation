{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faker\n",
    "\n",
    "from tensorflow.keras.layers import Concatenate, Input, LSTM, Attention, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from babel.dates import format_date\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the functiionality of the faker package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-11-09\n",
      "1971-05-14\n",
      "1984-12-29\n",
      "1982-03-03\n",
      "2010-02-24\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(fake.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "November 22, 2006\n",
      "Tuesday, August 21, 2018\n",
      "Sep 28, 1974\n",
      "1/1/93\n",
      "17 8 1971\n",
      "02 12 1981\n",
      "20 Jul 97\n",
      "13 June 1971\n",
      "3 November, 1980\n",
      "6 June 2005\n",
      "Thu, Sep 16, 1999\n",
      "Thursday, Jan 7, 82\n",
      "Friday, Feb 15, 2002\n",
      "Feb 16, 2014, Sunday\n",
      "Sun May 10 1970\n",
      "Friday Dec 6 2013\n"
     ]
    }
   ],
   "source": [
    "# test the fake date functionality\n",
    "print(format_date(fake.date_object(), format='long', locale='en'))\n",
    "\n",
    "print(format_date(fake.date_object(), format='full', locale='en'))\n",
    "\n",
    "print(format_date(fake.date_object(), format='medium', locale='en'))\n",
    "\n",
    "print(format_date(fake.date_object(), format='short', locale='en'))\n",
    "\n",
    "print(format_date(fake.date_object(), format='d M YYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='dd MM YYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='d MMM YY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='d MMMM YYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='d MMMM, ''YYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='d MMMM YYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='EEE, MMM d, ''YYYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='EEEE, MMM d, ''YY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='EEEE, MMM d, ''YYYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='MMM d, ''yyyy, EEEE', locale='en'))\n",
    "print(format_date(fake.date_object(), format='EEE MMM d ''YYYY', locale='en'))\n",
    "print(format_date(fake.date_object(), format='EEEE MMM d ''YYYY', locale='en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = [\n",
    "'long',\n",
    "'long',\n",
    "'long',\n",
    "'full',\n",
    "'full',\n",
    "'full',\n",
    "'medium',\n",
    "'medium',\n",
    "'medium',\n",
    "'short',\n",
    "'short',\n",
    "'short',\n",
    "'d M YYY',\n",
    "'dd MM YYY',\n",
    "'d MMM YY',\n",
    "'d MMMM YYY',\n",
    "'d MMMM, ''YYY',\n",
    "'d MMMM YYY',\n",
    "'EEE, MMM d, ''YYYY',\n",
    "'EEEE, MMM d, ''YY',\n",
    "'EEEE, MMM d, ''YYYY',\n",
    "'MMM d, ''yyyy, EEEE',\n",
    "'MMM dd, ''yyyy, EEEE',\n",
    "'EEE MMM d ''YYYY',\n",
    "'EEEE MMM d ''YYYY'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-01-23\n",
      "23 1 2008\n",
      "Jan 23, 2008\n"
     ]
    }
   ],
   "source": [
    "# example of the date in the standard format and a transformed one\n",
    "date = fake.date_object()\n",
    "print(date)\n",
    "print(format_date(date, format='d M YYY', locale='en'))\n",
    "print(format_date(date, format='medium', locale='en'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "date_to_transform = []\n",
    "\n",
    "human_vocab = set()\n",
    "machine_vocab = set()\n",
    "\n",
    "def generate_dataset(num_iterations):\n",
    "\n",
    "    for x in range(num_iterations):\n",
    "    \n",
    "        date = fake.date_object()\n",
    "        label.append(str(date))\n",
    "        machine_chars = list(str(date).lower())\n",
    "        machine_vocab.update(machine_chars)\n",
    "\n",
    "        date_new = format_date(date, format=random.choice(format), locale='en')\n",
    "        date_to_transform.append(str(date_new))\n",
    "        human_chars = list(str(date_new).lower().replace(',', ''))\n",
    "        human_vocab.update(human_chars)\n",
    "\n",
    "    return date_to_transform, label, human_vocab, machine_vocab\n",
    "\n",
    "date_to_transform, label, human_vocab, machine_vocab = generate_dataset(30000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1978-06-23'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6/23/78'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_transform[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab = sorted(machine_vocab)\n",
    "machine_vocab = {char: idx for idx, char in enumerate(machine_vocab)}\n",
    "machine_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vocab.update(['<unk>', '<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '/': 1,\n",
       " '0': 2,\n",
       " '1': 3,\n",
       " '2': 4,\n",
       " '3': 5,\n",
       " '4': 6,\n",
       " '5': 7,\n",
       " '6': 8,\n",
       " '7': 9,\n",
       " '8': 10,\n",
       " '9': 11,\n",
       " '<pad>': 12,\n",
       " '<unk>': 13,\n",
       " 'a': 14,\n",
       " 'b': 15,\n",
       " 'c': 16,\n",
       " 'd': 17,\n",
       " 'e': 18,\n",
       " 'f': 19,\n",
       " 'g': 20,\n",
       " 'h': 21,\n",
       " 'i': 22,\n",
       " 'j': 23,\n",
       " 'l': 24,\n",
       " 'm': 25,\n",
       " 'n': 26,\n",
       " 'o': 27,\n",
       " 'p': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'y': 35}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab = sorted(human_vocab)\n",
    "human_vocab = {char: idx for idx, char in enumerate(human_vocab)}\n",
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to transform: Jul 19, 1988 -- transformed text 1988-07-19\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(f'text to transform: {date_to_transform[i]} -- transformed text {label[i]}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max number of characters in human-format data\n",
    "Tx = 30\n",
    "# number of characters in machine-format data (default)\n",
    "Ty = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform strings to integer representations\n",
    "# if human data -- add unknown tokens and padding\n",
    "def string_to_int_human(string, length_max, vocab):\n",
    "\n",
    "    if len(string) > length_max:\n",
    "        string = string[:length_max]\n",
    "\n",
    "    representation = list(map(lambda x: vocab.get(x, vocab['<unk>']), string))\n",
    "\n",
    "    if len(string) < length_max:\n",
    "        representation += [vocab['<pad>']] * (length_max - len(string))\n",
    "\n",
    "    return representation\n",
    "\n",
    "def string_to_int_machine(string, length_max, vocab):\n",
    "\n",
    "    if len(string) > length_max:\n",
    "        string = string[:length_max]\n",
    "\n",
    "    representation = list(map(lambda x: vocab.get(x), string))\n",
    "\n",
    "    if len(string) < length_max:\n",
    "        representation += [vocab['<pad>']] * (length_max - len(string))\n",
    "\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2, 3, 0, 2, 2, 0, 1, 8]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_int_machine('2012-11-07', 10, machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfrom arrays of raw numbers to one-hot encodings\n",
    "def preprocess_data(date_to_transform, label,  human_vocab, machine_vocab, Tx, Ty):\n",
    "    \n",
    "    X = np.array([string_to_int_human(i, Tx, human_vocab) for i in date_to_transform])\n",
    "    Y = np.array([string_to_int_machine(t, Ty, machine_vocab) for t in label])\n",
    "    \n",
    "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
    "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
    "\n",
    "    return X, Y,  Xoh, Yoh\n",
    "\n",
    "X, Y, Xoh, Yoh = preprocess_data(date_to_transform, label, human_vocab, machine_vocab, Tx, Ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 30)\n",
      "(30000, 10)\n",
      "(30000, 30, 36)\n",
      "(30000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Xoh.shape)\n",
    "print(Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Architecture and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 36)]             0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 10, 11)]             0         []                            \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)         [(None, 30, 256),            300032    ['input_1[0][0]']             \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)         [(None, 10, 256),            274432    ['input_2[0][0]',             \n",
      "                              (None, 256),                           'encoder_lstm[0][1]',        \n",
      "                              (None, 256)]                           'encoder_lstm[0][2]']        \n",
      "                                                                                                  \n",
      " attention_layer (Attention  (None, 10, 256)              0         ['decoder_lstm[0][0]',        \n",
      " )                                                                   'encoder_lstm[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 10, 512)              0         ['decoder_lstm[0][0]',        \n",
      "                                                                     'attention_layer[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 10, 11)               5643      ['concatenate[0][0]']         \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 580107 (2.21 MB)\n",
      "Trainable params: 580107 (2.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uliana/botox/lib/python3.11/site-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "len_human_vocab = len(human_vocab)\n",
    "len_machine_vocab = len(machine_vocab)\n",
    "\n",
    "def model_attention(Tx, Ty, len_human_vocab, len_machine_vocab):\n",
    "\n",
    "    encoder_inputs = Input(shape=(Tx, len_human_vocab))\n",
    "    decoder_inputs = Input(shape=(Ty, len_machine_vocab))\n",
    "    \n",
    "    encoder_outputs, state_h, state_c = LSTM(256, return_sequences=True, return_state=True, name='encoder_lstm')(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    decoder_outputs, _, _  = LSTM(256, return_sequences=True, return_state=True, name='decoder_lstm')(decoder_inputs, initial_state=encoder_states)\n",
    "    \n",
    "    attention = Attention(name='attention_layer')([decoder_outputs, encoder_outputs])\n",
    "\n",
    "    concat = Concatenate(axis=-1)([decoder_outputs, attention])\n",
    "    \n",
    "    decoder = TimeDistributed(Dense(len_machine_vocab, activation='softmax'))(concat)\n",
    "    \n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_attention(Tx, Ty, len_human_vocab, len_machine_vocab)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xoh, Yoh, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1720353328.688865       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - ETA: 0s - loss: 0.7026 - accuracy: 0.7298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720353441.877983       1 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" model: \"0\" frequency: 2400 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"ARM NEON\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 16384 l2_cache_size: 524288 l3_cache_size: 524288 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280/1280 [==============================] - 121s 94ms/step - loss: 0.7026 - accuracy: 0.7298 - val_loss: 0.2661 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "1280/1280 [==============================] - 120s 94ms/step - loss: 0.1251 - accuracy: 0.9595 - val_loss: 0.0505 - val_accuracy: 0.9856\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - 144s 113ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0206 - val_accuracy: 0.9956\n",
      "Epoch 4/10\n",
      "1280/1280 [==============================] - 131s 103ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0264 - val_accuracy: 0.9932\n",
      "Epoch 5/10\n",
      "1280/1280 [==============================] - 123s 96ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0114 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "1280/1280 [==============================] - 39s 31ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "1280/1280 [==============================] - 40s 31ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 8/10\n",
      "1280/1280 [==============================] - 41s 32ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
      "Epoch 9/10\n",
      "1280/1280 [==============================] - 41s 32ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 10/10\n",
      "1280/1280 [==============================] - 40s 32ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9997\n"
     ]
    }
   ],
   "source": [
    "# add special token \n",
    "decoder_input_data = np.zeros(Y_train.shape)\n",
    "decoder_input_data[:, 1:, :] = Y_train[:, :-1, :]\n",
    "decoder_input_data[:, 0, 0] = 1\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    [X_train, decoder_input_data],\n",
    "    Y_train,\n",
    "    batch_size=15,\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('model_attention.keras')\n",
    "\n",
    "# Load the model\n",
    "model = keras.models.load_model('model_attention.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0314 - accuracy: 0.9888\n",
      "Accuracy on test data: 98.88%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([X_test, np.zeros((len(X_test), Ty, len(machine_vocab)))], Y_test)\n",
    "print(f'Accuracy on test data: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 2s 11ms/step\n",
      "Predicted:  1970-07-30\n",
      "Label:  1970-07-30\n",
      "Predicted:  2012-03-20\n",
      "Label:  2012-03-20\n",
      "Predicted:  1991-01-04\n",
      "Label:  1991-01-04\n",
      "Predicted:  2009-02-28\n",
      "Label:  2009-02-28\n",
      "Predicted:  2012-01-21\n",
      "Label:  2012-01-21\n",
      "Predicted:  1992-12-15\n",
      "Label:  1992-12-15\n",
      "Predicted:  1991-05-17\n",
      "Label:  1991-05-17\n",
      "Predicted:  2001-11-23\n",
      "Label:  2001-11-23\n",
      "Predicted:  1990-03-22\n",
      "Label:  1990-03-21\n",
      "Predicted:  1985-03-02\n",
      "Label:  1985-03-02\n"
     ]
    }
   ],
   "source": [
    "# Check the prediction in the human readable format\n",
    "\n",
    "# create a reverse dictionary and return a string\n",
    "def one_hot_to_str(oh, vocab):\n",
    "    val_to_char = {val: char for char, val in vocab.items()}\n",
    "    string =  ''.join(val_to_char[np.argmax(vec)] for vec in oh)\n",
    "    return string\n",
    "\n",
    "def predict(model, X_test, machine_vocab, Ty):\n",
    "\n",
    "    prediction = model.predict([X_test, np.zeros((len(X_test), Ty, len(machine_vocab)))])\n",
    "    prediction = [one_hot_to_str(pred, machine_vocab) for pred in prediction]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "prediction = predict(model,X_test, machine_vocab, Ty)\n",
    "\n",
    "for i in range(10):\n",
    "    print('Predicted: ', prediction[i])\n",
    "    print('Label: ', one_hot_to_str(Y_test[i], machine_vocab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
